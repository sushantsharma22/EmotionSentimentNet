nohup: ignoring input
Using device: cuda
Checking GPU information...

Number of GPUs available: 3

--- GPU 0 Info ---
Name: NVIDIA A16
Capability: (8, 6)
Memory Allocated: 0.00 MB
Max Memory Allocated: 0.00 MB
Memory Reserved: 0.00 MB
Max Memory Reserved: 0.00 MB

--- GPU 1 Info ---
Name: NVIDIA A16
Capability: (8, 6)
Memory Allocated: 0.00 MB
Max Memory Allocated: 0.00 MB
Memory Reserved: 0.00 MB
Max Memory Reserved: 0.00 MB

--- GPU 2 Info ---
Name: NVIDIA A16
Capability: (8, 6)
Memory Allocated: 0.00 MB
Max Memory Allocated: 0.00 MB
Memory Reserved: 0.00 MB
Max Memory Reserved: 0.00 MB


Splitting dataset...
Dataset split into 333447 train, 41681 val, 41681 test samples.
Dataset split completed.

Starting training process...
CUDA_VISIBLE_DEVICES: 0,1,3
Using 3 GPUs with DataParallel!
Resuming training from checkpoint: ./checkpoint_latest.pt
Resuming from epoch 3

--- Starting Epoch 3/10 ---
Epoch 3:   0%|          | 0/1094 [00:00<?, ?batch/s]Epoch 3:   0%|          | 0/1094 [00:10<?, ?batch/s]
Traceback (most recent call last):
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/main.py", line 62, in <module>
    main()
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/main.py", line 53, in main
    fit_emotion_model(df_train, df_val)
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/trainer.py", line 180, in fit_emotion_model
    train_emotion_classifier(model, optimizer, scaler, train_loader, val_loader, start_epoch=start_epoch)
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/trainer.py", line 84, in train_emotion_classifier
    logits, sentiment_output = model(input_ids, attention_mask)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 193, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py", line 212, in parallel_apply
    return parallel_apply(
           ^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py", line 126, in parallel_apply
    output.reraise()
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/_utils.py", line 733, in reraise
    raise exception
torch.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py", line 96, in _worker
    output = module(*input, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/multi_task_model.py", line 19, in forward
    outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 870, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 674, in forward
    output_states, attn_weights = layer_module(
                                  ^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 450, in forward
    intermediate_output = self.intermediate(attention_output)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 405, in forward
    hidden_states = self.intermediate_act_fn(hidden_states)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sharm2s1/PycharmProjects/Emotional analysis/venv/lib/python3.11/site-packages/transformers/activations.py", line 78, in forward
    return self.act(input)
           ^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 14.54 GiB of which 27.75 MiB is free. Including non-PyTorch memory, this process has 14.49 GiB memory in use. Of the allocated memory 14.23 GiB is allocated by PyTorch, and 77.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

